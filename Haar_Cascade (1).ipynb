{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Haar Cascade.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMicbuSr1Auh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VydMGrSd4W42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagePaths = list(paths.list_images('/content/drive/My Drive/face_detection_dataset'))\n",
        "data = []\n",
        "labels = []\n",
        "for imagePath in imagePaths:\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  image = load_img(imagePath, target_size=(224,224))\n",
        "  image = img_to_array(image)\n",
        "  image = preprocess_input(image)\n",
        "  data.append(image)\n",
        "  labels.append(label)\n",
        "\n",
        "data = np.array(data, dtype='float32')\n",
        "labels = np.array(labels)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RziGLzIiEUyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseModel = MobileNetV2(input_shape=(224,224,3), weights = 'imagenet', include_top=False)\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7,7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "model = Model(inputs = baseModel.input, outputs = headModel)\n",
        "for layer in baseModel.layers:\n",
        "  layer.trainable = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pm_ReLGwi68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.20, stratify=labels, random_state=42)\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm9V2Pj81Vkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #Initial Learning Rate\n",
        "INIT_LR = 1e-4    \n",
        "#Number of EPOCHS     \n",
        "EPOCHS = 20\n",
        "#Batch Size             \n",
        "BS = 32                 \n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeBesV7H3U4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eemw2an96Juf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To save the trained model\n",
        "model.save('mask_recog.h5')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvpPeXUPvJJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/opencv/opencv.git\n",
        "!mkdir Video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kgdQnvzvKiL",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Java script code to access webcam\n",
        "!pip install ffmpeg-python\n",
        "\n",
        "\n",
        "from IPython.display import HTML, Javascript, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "video_file_test = '/content/Video/osy_test.mp4' \n",
        "  \n",
        "\n",
        "VIDEO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var my_btn_txt = document.createTextNode(\"Press to start recording\");\n",
        "my_btn.appendChild(my_btn_txt);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, videoStream;\n",
        "var recordButton = my_btn;\n",
        "var handleSuccess = function(stream) {\n",
        "  videoStream = stream;\n",
        "  var options = {  \n",
        "    mimeType : 'video/webm;codecs=vp9'  \n",
        "  };            \n",
        "  recorder = new MediaRecorder(stream, options);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('video');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "navigator.mediaDevices.getUserMedia({video: true}).then(handleSuccess);\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      videoStream.getVideoTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... Please wait!\"\n",
        "  }\n",
        "}\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "var data = new Promise(resolve=>{\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available\n",
        "  resolve(base64data.toString())\n",
        "});\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def start_webcam():\n",
        "  js = Javascript('''\n",
        "    async function startWebcam() {\n",
        "      const div = document.createElement('div');\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      \n",
        "      return;\n",
        "    }\n",
        "    ''')\n",
        "  \n",
        "  display(js)\n",
        "  data = eval_js('startWebcam()')\n",
        "  \n",
        "    \n",
        "start_webcam()\n",
        "\n",
        "def get_video():\n",
        "  display(HTML(VIDEO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  return binary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT33HfTcvlpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "videofile = get_video()\n",
        "with open(video_file_test, 'wb') as f:\n",
        "  f.write(videofile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaCOgpDSohjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "cascPath = os.path.dirname(\n",
        "    cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
        "\n",
        "faceCascade = cv2.CascadeClassifier(cascPath)\n",
        "model = load_model(\"mask_recog.h5\")\n",
        "\n",
        "video_capture = cv2.VideoCapture(video_file_test)\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = video_capture.read()\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = faceCascade.detectMultiScale(gray,\n",
        "                                         scaleFactor=1.1,\n",
        "                                         minNeighbors=5,\n",
        "                                         minSize=(60, 60),\n",
        "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "    faces_list=[]\n",
        "    preds=[]\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_frame = frame[y:y+h,x:x+w]\n",
        "        face_frame = cv2.cvtColor(face_frame, cv2.COLOR_BGR2RGB)\n",
        "        face_frame = cv2.resize(face_frame, (224, 224))\n",
        "        face_frame = img_to_array(face_frame)\n",
        "        face_frame = np.expand_dims(face_frame, axis=0)\n",
        "        face_frame =  preprocess_input(face_frame)\n",
        "        faces_list.append(face_frame)\n",
        "        if len(faces_list)>0:\n",
        "            preds = model.predict(faces_list)\n",
        "        for pred in preds:\n",
        "            (mask, withoutMask) = pred\n",
        "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
        "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
        "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "        cv2.putText(frame, label, (x, y- 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h),color, 2)\n",
        "        # Display the resulting frame\n",
        "    cv2_imshow(frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}